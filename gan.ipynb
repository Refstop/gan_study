{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44f698d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import hstack\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import sin,pi\n",
    "from numpy.random import rand, randn\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter, AutoMinorLocator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c1768c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n):\n",
    "        # 가우시안 분포로부터 데이터 벡터를 추출\n",
    "        z_input = randn(latent_dim * n)\n",
    "        # 네트워크에 입력할 배치 형태로 재구성\n",
    "        z_input = z_input.reshape(n, latent_dim)\n",
    "        return z_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0003a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자 모델을 학습하는 레이어 구성\n",
    "def define_generator(latent_dim, n_outputs= 2):\n",
    "        model = Sequential()\n",
    "#       model.add(Dense(15, activation='relu', kernel_initializer='he_uniform', input_dim=latent_dim))\n",
    "        model.add(Dense(15, activation='relu', input_dim=latent_dim))\n",
    "        model.add(Dense(n_outputs, activation='linear'))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35ad6c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구별자 모델 학습 레이어 구성\n",
    "def define_discriminator(n_inputs= 2):\n",
    "        model = Sequential()\n",
    "#       model.add(Dense(25, activation='relu', kernel_initializer='he_uniform', input_dim=n_inputs))\n",
    "        model.add(Dense(25, activation='relu', input_dim=n_inputs))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        #     compile model\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eae8da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#       define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(generator, discriminator):\n",
    "        #     make weights in the discriminator not trainable\n",
    "        discriminator.trainable = False\n",
    "        #     connect them\n",
    "        model = Sequential()\n",
    "        # 아래 두 줄을 거치는 것이 D(G(z))의 결과와 같다\n",
    "        #     add generator\n",
    "        model.add(generator)\n",
    "        #     add the discriminator\n",
    "        model.add(discriminator) # D(G(z))\n",
    "        #     compile model\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36253146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real samples, 트레이닝 데이터에 해당\n",
    "def generate_real_samples(n):\n",
    "        #     generate inputs in [-0.5, 0.5]*2.*pi\n",
    "        p = (rand(n) - 0.5)*2.*pi\n",
    "        #     generate outputs sin(x)\n",
    "        q = sin(p)\n",
    "        #     stack arrays\n",
    "        p = p.reshape(n, 1)\n",
    "        q = q.reshape(n, 1)\n",
    "        x = hstack((p, q))\n",
    "        #     generate class labels\n",
    "        y = ones((n, 1))\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5921057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#       use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n):\n",
    "        #     generate points in latent space\n",
    "        z_input = generate_latent_points(latent_dim, n)\n",
    "        #     predict outputs\n",
    "        x = generator.predict(z_input)\n",
    "        #     create class labels\n",
    "        y = zeros((n, 1))\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7d6a573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(epoch, generator, discriminator, latent_dim, n=100):\n",
    "        #     prepare real samples\n",
    "        x_real, y_real = generate_real_samples(n)\n",
    "        #     evaluate discriminator on real examples\n",
    "        _, acc_real = discriminator.evaluate(x_real, y_real, verbose=0)\n",
    "        #     prepare fake examples\n",
    "        x_fake, y_fake = generate_fake_samples(generator, latent_dim, n)\n",
    "        #     evaluate discriminator on fake examples\n",
    "        _, acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n",
    "        #     summarize discriminator performance\n",
    "        print(epoch, acc_real, acc_fake)\n",
    "        #     scatter plot real and fake data points\n",
    "        pyplot.figure(figsize=(6,4))\n",
    "        ax=pyplot.axes()\n",
    "        ax.set_xlabel(r'$alpha$',fontsize=20)\n",
    "        ax.set_ylabel(r'$beta$',fontsize=20)\n",
    "#       ax.legend(fancybox=True, shadow=True, fontsize=15, framealpha=0.8)\n",
    "        majorLocator= MultipleLocator(1)\n",
    "        minorLocator= AutoMinorLocator()\n",
    "        majorFormatter= FormatStrFormatter('%d')\n",
    "        minorFormatter= FormatStrFormatter('%d')\n",
    "        ax.xaxis.set_major_locator(majorLocator)\n",
    "        ax.xaxis.set_major_formatter(majorFormatter)\n",
    "        ax.xaxis.set_minor_locator(minorLocator)\n",
    "        majorLocator= MultipleLocator(1)\n",
    "        minorLocator= AutoMinorLocator()\n",
    "        majorFormatter= FormatStrFormatter('%d')\n",
    "        minorFormatter= FormatStrFormatter('%d')\n",
    "        ax.yaxis.set_major_locator(majorLocator)\n",
    "        ax.yaxis.set_major_formatter(majorFormatter)\n",
    "        ax.yaxis.set_minor_locator(minorLocator)\n",
    "        ax.tick_params(which='major', length=2, color='black')\n",
    "        ax.tick_params(which='minor', length=4, color='brown')\n",
    "        ax.set_facecolor(\"beige\")\n",
    "        pyplot.grid(True)\n",
    "        pyplot.scatter(x_real[:, 0], x_real[:, 1], color='red', s=5)\n",
    "        pyplot.scatter(x_fake[:, 0], x_fake[:, 1], color='blue', s=5)\n",
    "        pyplot.tight_layout()\n",
    "        str1='sin'+str(epoch)+'.pdf'\n",
    "        pyplot.savefig(str1,dpi=150)\n",
    "#         pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86f61035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#       train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, latent_dim, n_epochs=100000, n_batch=128, n_eval=2000):\n",
    "        #    determine half the size of one batch, for updating the discriminator\n",
    "        half_batch = int(n_batch / 2)\n",
    "        #    manually enumerate epochs\n",
    "        for i in range(n_epochs):\n",
    "                #     prepare real samples\n",
    "                x_real, y_real = generate_real_samples(half_batch)\n",
    "                #     prepare fake examples\n",
    "                x_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "                #     update discriminator\n",
    "                d_model.train_on_batch(x_real, y_real)\n",
    "                d_model.train_on_batch(x_fake, y_fake)\n",
    "                #     prepare points in latent space as input for the generator\n",
    "                x_gan = generate_latent_points(latent_dim, n_batch)\n",
    "                #     create inverted labels for the fake samples\n",
    "                y_gan = ones((n_batch, 1))\n",
    "                #     update the generator via the discriminator's error\n",
    "                gan_model.train_on_batch(x_gan, y_gan)\n",
    "                #     evaluate the model every n_eval epochs\n",
    "                if (i+1) % n_eval == 0:\n",
    "                        summarize_performance(i, g_model, d_model, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aa5ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 02:30:10.331381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 02:30:10.340283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 02:30:10.340669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 02:30:10.341489: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-07 02:30:10.341840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 02:30:10.342182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 02:30:10.342482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 02:30:10.749755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 02:30:10.750079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 02:30:10.750351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 02:30:10.750638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4090 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-04-07 02:30:11.696495: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-04-07 02:30:15.894624: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:30:20.979378: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:30:25.999619: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:30:46.411433: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:30:46.423386: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:30:51.515925: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:31:12.521774: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:31:17.953229: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:31:36.838453: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:31:36.862202: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:31:39.457403: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:31:44.785513: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:31:45.223471: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:31:45.707067: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:31:47.549371: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:31:49.579339: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999 0.46000000834465027 0.6899999976158142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 02:32:14.616277: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:32:16.672423: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:32:23.051396: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:32:23.148876: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:32:28.749024: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:32:32.868537: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:32:39.169170: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:32:44.747089: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:32:44.849844: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:33:07.072735: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:33:07.087267: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:33:12.741884: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:33:23.933464: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:33:29.415145: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-04-07 02:33:35.447343: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    }
   ],
   "source": [
    "#     size of the latent space\n",
    "latent_dim = 10\n",
    "#     create the discriminator\n",
    "discriminator = define_discriminator()\n",
    "#     create the generator\n",
    "generator = define_generator(latent_dim)\n",
    "#     create the GAN\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "#      train model\n",
    "train(generator, discriminator, gan_model, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc1e7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
